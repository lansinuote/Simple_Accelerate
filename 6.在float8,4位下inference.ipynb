{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58ff2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0149,  0.0021, -0.0038,  ..., -0.0374,  0.0096, -0.0205],\n",
       "        [ 0.0344,  0.0049,  0.0069,  ...,  0.0158, -0.0057,  0.0022],\n",
       "        [ 0.0015,  0.0119, -0.0005,  ..., -0.0297, -0.0113,  0.0088],\n",
       "        ...,\n",
       "        [-0.0055,  0.0014, -0.0045,  ..., -0.0159,  0.0410,  0.0066],\n",
       "        [ 0.0322,  0.0062,  0.0114,  ..., -0.0229,  0.0273, -0.0221],\n",
       "        [ 0.0206,  0.0042, -0.0416,  ..., -0.0254, -0.0082, -0.0046]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from functions import get_model\n",
    "\n",
    "model, _, _ = get_model()\n",
    "\n",
    "#保存测试模型\n",
    "Accelerator().save_model(model,\n",
    "                         'model/accelerator.save_model',\n",
    "                         max_shard_size='500MB',\n",
    "                         safe_serialization=True)\n",
    "\n",
    "model.classifier.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7572aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is not recommended to quantize a loaded model. The model should be instantiated under the `init_empty_weights` context manager.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0149,  0.0021, -0.0038,  ..., -0.0374,  0.0096, -0.0205],\n",
       "        [ 0.0344,  0.0049,  0.0069,  ...,  0.0158, -0.0057,  0.0022],\n",
       "        [ 0.0015,  0.0119, -0.0005,  ..., -0.0297, -0.0113,  0.0088],\n",
       "        ...,\n",
       "        [-0.0055,  0.0014, -0.0045,  ..., -0.0159,  0.0410,  0.0066],\n",
       "        [ 0.0322,  0.0062,  0.0114,  ..., -0.0229,  0.0273, -0.0221],\n",
       "        [ 0.0206,  0.0042, -0.0416,  ..., -0.0254, -0.0082, -0.0046]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from accelerate.utils import load_and_quantize_model, BnbQuantizationConfig\n",
    "\n",
    "#使用float8\n",
    "bnb_quantization_config = BnbQuantizationConfig(load_in_8bit=True,\n",
    "                                                llm_int8_threshold=6)\n",
    "\n",
    "#使用float4\n",
    "bnb_quantization_config = BnbQuantizationConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type='nf4')\n",
    "\n",
    "load_and_quantize_model(model,\n",
    "                        weights_location='model/save_pretrained',\n",
    "                        device_map='auto',\n",
    "                        bnb_quantization_config=bnb_quantization_config)\n",
    "\n",
    "model.classifier.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc857539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62\n",
      "1 62\n",
      "2 62\n",
      "3 62\n",
      "4 62\n",
      "5 62\n",
      "6 62\n",
      "7 62\n",
      "8 62\n",
      "9 62\n",
      "10 62\n",
      "11 62\n",
      "12 62\n",
      "13 62\n",
      "14 62\n",
      "15 62\n",
      "16 62\n",
      "17 62\n",
      "18 62\n",
      "19 62\n",
      "20 62\n",
      "21 62\n",
      "22 62\n",
      "23 62\n",
      "24 62\n",
      "25 62\n",
      "26 62\n",
      "27 62\n",
      "28 62\n",
      "29 62\n",
      "30 62\n",
      "31 62\n",
      "32 62\n",
      "33 62\n",
      "34 62\n",
      "35 62\n",
      "36 62\n",
      "37 62\n",
      "38 62\n",
      "39 62\n",
      "40 62\n",
      "41 62\n",
      "42 62\n",
      "43 62\n",
      "44 62\n",
      "45 62\n",
      "46 62\n",
      "47 62\n",
      "48 62\n",
      "49 62\n",
      "50 62\n",
      "51 62\n",
      "52 62\n",
      "53 62\n",
      "54 62\n",
      "55 62\n",
      "56 62\n",
      "57 62\n",
      "58 62\n",
      "59 62\n",
      "60 62\n",
      "61 62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=11, microseconds=385756)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions import get_loader\n",
    "import datetime\n",
    "\n",
    "_, _, loader = get_loader()\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "for i, data in enumerate(loader):\n",
    "    with torch.no_grad():\n",
    "        model(**data.to('cuda'))\n",
    "    print(i, len(loader))\n",
    "\n",
    "datetime.datetime.now() - now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
