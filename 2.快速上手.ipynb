{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3865d825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cuda117/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62 2.447235107421875 0.0001 0.03125\n",
      "1 62 2.36968994140625 0.0001 0.03125\n",
      "2 62 2.384185791015625 0.0001 0.125\n",
      "3 62 2.410858154296875 9.990133642141359e-05 0.0\n",
      "4 62 1.7743988037109375 9.990133642141359e-05 0.375\n",
      "5 62 1.9027099609375 9.990133642141359e-05 0.21875\n",
      "6 62 1.891082763671875 9.990133642141359e-05 0.34375\n",
      "7 62 1.7799530029296875 9.96057350657239e-05 0.3125\n",
      "8 62 1.593292236328125 9.96057350657239e-05 0.5\n",
      "9 62 1.4858932495117188 9.96057350657239e-05 0.59375\n",
      "10 62 1.5505752563476562 9.96057350657239e-05 0.4375\n",
      "11 62 1.83154296875 9.911436253643445e-05 0.3125\n",
      "12 62 1.01068115234375 9.911436253643445e-05 0.625\n",
      "13 62 0.9045181274414062 9.911436253643445e-05 0.71875\n",
      "14 62 0.8840827941894531 9.911436253643445e-05 0.71875\n",
      "15 62 1.1139945983886719 9.842915805643155e-05 0.5\n",
      "16 62 0.5190963745117188 9.842915805643155e-05 0.9375\n",
      "17 62 0.5722999572753906 9.842915805643155e-05 0.90625\n",
      "18 62 0.5345573425292969 9.842915805643155e-05 0.90625\n",
      "19 62 0.5995712280273438 9.755282581475769e-05 0.90625\n",
      "20 62 0.3807258605957031 9.755282581475769e-05 0.96875\n",
      "21 62 0.35436439514160156 9.755282581475769e-05 0.9375\n",
      "22 62 0.36093902587890625 9.755282581475769e-05 0.96875\n",
      "23 62 0.3515968322753906 9.648882429441257e-05 0.9375\n",
      "24 62 0.3170490264892578 9.648882429441257e-05 0.9375\n",
      "25 62 0.3921775817871094 9.648882429441257e-05 0.875\n",
      "26 62 0.3772106170654297 9.648882429441257e-05 0.875\n",
      "27 62 0.47879981994628906 9.524135262330098e-05 0.84375\n",
      "28 62 0.16826248168945312 9.524135262330098e-05 1.0\n",
      "29 62 0.1696319580078125 9.524135262330098e-05 1.0\n",
      "30 62 0.1526641845703125 9.524135262330098e-05 1.0\n",
      "31 62 0.1447887420654297 9.381533400219318e-05 1.0\n",
      "32 62 0.10026073455810547 9.381533400219318e-05 1.0\n",
      "33 62 0.1293325424194336 9.381533400219318e-05 1.0\n",
      "34 62 0.10203742980957031 9.381533400219318e-05 1.0\n",
      "35 62 0.11065006256103516 9.221639627510076e-05 1.0\n",
      "36 62 0.07334518432617188 9.221639627510076e-05 1.0\n",
      "37 62 0.08250951766967773 9.221639627510076e-05 1.0\n",
      "38 62 0.08044052124023438 9.221639627510076e-05 1.0\n",
      "39 62 0.07616186141967773 9.045084971874738e-05 1.0\n",
      "40 62 0.0593266487121582 9.045084971874738e-05 1.0\n",
      "41 62 0.05658102035522461 9.045084971874738e-05 1.0\n",
      "42 62 0.06016683578491211 9.045084971874738e-05 1.0\n",
      "43 62 0.06713294982910156 8.852566213878947e-05 1.0\n",
      "44 62 0.052820682525634766 8.852566213878947e-05 1.0\n",
      "45 62 0.04671478271484375 8.852566213878947e-05 1.0\n",
      "46 62 0.04523420333862305 8.852566213878947e-05 1.0\n",
      "47 62 0.04641866683959961 8.644843137107059e-05 1.0\n",
      "48 62 0.04667091369628906 8.644843137107059e-05 1.0\n",
      "49 62 0.041161537170410156 8.644843137107059e-05 1.0\n",
      "50 62 0.04080915451049805 8.644843137107059e-05 1.0\n",
      "51 62 0.03752946853637695 8.422735529643444e-05 1.0\n",
      "52 62 0.0307159423828125 8.422735529643444e-05 1.0\n",
      "53 62 0.031208038330078125 8.422735529643444e-05 1.0\n",
      "54 62 0.035132408142089844 8.422735529643444e-05 1.0\n",
      "55 62 0.02884674072265625 8.18711994874345e-05 1.0\n",
      "56 62 0.02396416664123535 8.18711994874345e-05 1.0\n",
      "57 62 0.02453470230102539 8.18711994874345e-05 1.0\n",
      "58 62 0.0242159366607666 8.18711994874345e-05 1.0\n",
      "59 62 0.025388002395629883 7.938926261462366e-05 1.0\n",
      "60 62 0.020090818405151367 7.938926261462366e-05 1.0\n",
      "61 62 0.021314144134521484 7.679133974894983e-05 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=14, microseconds=139662)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from functions import get_loader, get_model\n",
    "from accelerate import Accelerator\n",
    "import datetime\n",
    "\n",
    "_, _, loader = get_loader()\n",
    "model, optimizer, scheduler = get_model()\n",
    "\n",
    "#使用4步梯度累积\n",
    "#可以修改这里的mixed_precision,来查看不同精度的时间差,显存差\n",
    "#no,fp8,fp16,bf16\n",
    "accelerator = Accelerator(gradient_accumulation_steps=4,\n",
    "                          mixed_precision='fp16')\n",
    "\n",
    "loader, model, optimizer, scheduler = accelerator.prepare(\n",
    "    loader, model, optimizer, scheduler)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "for i, data in enumerate(loader):\n",
    "    #在这个范围内累积梯度\n",
    "    with accelerator.accumulate(model):\n",
    "        out = model(**data)\n",
    "        accelerator.backward(out.loss)\n",
    "        if accelerator.sync_gradients:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "        labels = data['labels']\n",
    "        logits = out['logits'].argmax(1)\n",
    "        acc = (labels == logits).sum().item() / len(labels)\n",
    "\n",
    "        print(i, len(loader), out.loss.item(), lr, acc)\n",
    "\n",
    "datetime.datetime.now() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f38d8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n",
      "f runed\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "\n",
    "def f():\n",
    "    print('f runed')\n",
    "\n",
    "\n",
    "#在jupyter中也可以这样运行,主要就是可以增加一些参数\n",
    "notebook_launcher(f, num_processes=0, mixed_precision='fp16')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
